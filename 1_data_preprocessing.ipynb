{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "import chardet\n",
    "import datetime as dt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding: ISO-8859-1\n"
     ]
    }
   ],
   "source": [
    "csv_dir = \"data_stations/raw_data/*\"\n",
    "files = glob.glob(csv_dir)\n",
    "file = files[0] # exemplo de arquivo, só para identificação do padrão de encoding\n",
    "\n",
    "def encoding_detection(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        result = chardet.detect(f.read())\n",
    "        return result['encoding']\n",
    "\n",
    "encodig = encoding_detection(file)\n",
    "\n",
    "print(f'Encoding: {encodig}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing and data insertion on database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas do dataset:\n",
      "\n",
      "id_estacao                                                  object\n",
      "nome_estacao                                                object\n",
      "timestamp                                           datetime64[ns]\n",
      "precipitacao total (mm)                                    float64\n",
      "pressao atmosferica (mb)                                   float64\n",
      "pressao atmosferica max. (mb)                              float64\n",
      "pressao atmosferica min. na hora ant. (aut) (mb)           float64\n",
      "radiacao global (kj/m2)                                    float64\n",
      "temperatura do ar - bulbo seco(c)                          float64\n",
      "temperatura do ponto de orvalho (c)                        float64\n",
      "temperatura maxima (c)                                     float64\n",
      "temperatura minima (c)                                     float64\n",
      "temperatura orvalho max. (c)                               float64\n",
      "temperatura orvalho min. (c)                               float64\n",
      "umidade rel. max. (%)                                      float64\n",
      "umidade rel. min. (%)                                      float64\n",
      "umidade relativa do ar (%)                                 float64\n",
      "vento, direcao (gr)                                        float64\n",
      "vento, rajada max. (m/s)                                   float64\n",
      "vento velocidade (m/s)]                                    float64\n",
      "dtype: object\n",
      "\n",
      "Quantidade dados NaN: id_estacao                                                 0\n",
      "nome_estacao                                               0\n",
      "timestamp                                                  0\n",
      "precipitacao total (mm)                              4971461\n",
      "pressao atmosferica (mb)                            20460222\n",
      "pressao atmosferica max. (mb)                       20460680\n",
      "pressao atmosferica min. na hora ant. (aut) (mb)    20462474\n",
      "radiacao global (kj/m2)                             20707638\n",
      "temperatura do ar - bulbo seco(c)                   20455665\n",
      "temperatura do ponto de orvalho (c)                 20495852\n",
      "temperatura maxima (c)                              20457930\n",
      "temperatura minima (c)                              20457989\n",
      "temperatura orvalho max. (c)                        20497587\n",
      "temperatura orvalho min. (c)                        20499043\n",
      "umidade rel. max. (%)                                3397313\n",
      "umidade rel. min. (%)                                3406312\n",
      "umidade relativa do ar (%)                           3380525\n",
      "vento, direcao (gr)                                  3620195\n",
      "vento, rajada max. (m/s)                            19454251\n",
      "vento velocidade (m/s)]                             18506306\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "csv_dir = \"data_stations/raw_data/*\"\n",
    "files = glob.glob(csv_dir)\n",
    "\n",
    "# Criação de uma pasta que receberá os arquivos csv configurados/pre-processados\n",
    "destiny_folder = \"data_stations/preprocessed_data\"      \n",
    "if not os.path.exists(destiny_folder):\n",
    "    os.makedirs(destiny_folder)\n",
    "\n",
    "cols_to_use = list(range(19))\n",
    "rows_to_skip = list(range(9))\n",
    "\n",
    "datasets = []\n",
    "\n",
    "df_concat = pd.DataFrame()\n",
    "\n",
    "\n",
    "for idx, file in enumerate(files):\n",
    "    \n",
    "    file_name = file.split(\"\\\\\")[-1]\n",
    "    \n",
    "    data = pd.read_csv(file, encoding=encodig, sep=\";\",\n",
    "                    skiprows=rows_to_skip , header=None, usecols=cols_to_use)\n",
    "\n",
    "    cols_renamed = \"Data;Hora UTC;PRECIPITACAO TOTAL (mm);PRESSAO ATMOSFERICA (mB);PRESSAO ATMOSFERICA MAX. (mB);PRESSAO ATMOSFERICA MIN. NA HORA ANT. (AUT) (mB);RADIACAO GLOBAL (Kj/m2);TEMPERATURA DO AR - BULBO SECO(C);TEMPERATURA DO PONTO DE ORVALHO (C);TEMPERATURA MAXIMA (C);TEMPERATURA MINIMA (C);TEMPERATURA ORVALHO MAX. (C);TEMPERATURA ORVALHO MIN. (C);UMIDADE REL. MAX. (%);UMIDADE REL. MIN. (%);UMIDADE RELATIVA DO AR (%);VENTO, DIRECAO (gr);VENTO, RAJADA MAX. (m/s);VENTO VELOCIDADE (m/s)]\"      \n",
    "    cols_renamed = cols_renamed.lower().split(\";\")\n",
    "\n",
    "    data.columns = cols_renamed\n",
    "\n",
    "    # conversão das células que foram lidas como não numéricas para numéricas\n",
    "    cols_to_convert = [x for x in cols_renamed if x not in ['data', 'hora utc']]\n",
    "    \n",
    "    for col in cols_to_convert:\n",
    "        data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "        \n",
    "    # substituição dos valores inválidos (-9999) por NaN\n",
    "    data = data.replace(-9999, np.nan)\n",
    "\n",
    "    # Conversão para timestamp\n",
    "    # não esquecer que todas os nomes de colunas havia sido convertidas para minusculo\n",
    "    try:\n",
    "        data[\"timestamp\"] = data[\"data\"] + ' ' + data[\"hora utc\"] + ':00'\n",
    "        data['timestamp'] = data['timestamp'].apply(lambda x: dt.datetime.strptime(str(x), '%Y-%m-%d %H:%M:%S'))\n",
    "        \n",
    "    except ValueError:\n",
    "        data[\"timestamp\"] = data[\"data\"] + ' ' + data[\"hora utc\"].str[0:2] + ':00:00'\n",
    "        data['timestamp'] = data['timestamp'].apply(lambda x: dt.datetime.strptime(str(x), '%Y/%m/%d %H:%M:%S'))\n",
    "        \n",
    "    data = data.drop([\"data\", \"hora utc\"], axis=1) #eliminação das colunas data e hora, que não serão mais necessárias com o timestamp\n",
    "    \n",
    "    # definindo uma coluna que guarda o nome da estação\n",
    "    station= file_name.split(\"_\")[4]\n",
    "    data[\"nome_estacao\"] = station\n",
    "\n",
    "    # Importante! Como os nomes das estações podem se repetir, é bm armazenar o ID de cada uma\n",
    "    id_station= file_name.split(\"_\")[3]\n",
    "    data[\"id_estacao\"] = id_station\n",
    "    \n",
    "    # reorganizando as colunas de maneira que o nome da estação e a data apareceçam antes das medidas\n",
    "    ordered_cols = ['id_estacao', 'nome_estacao', 'timestamp'] + [x for x in cols_renamed if x not in ['data', 'hora utc']]\n",
    "    data = data[ordered_cols]\n",
    "    \n",
    "    datasets.append(data)\n",
    "        \n",
    "    # validação, indicando quais colunas restaram e seus tipos, pós preprocessadas\n",
    "    if idx == 0:\n",
    "        print(\"Colunas do dataset:\\n\")\n",
    "        print(data.dtypes)\n",
    "        \n",
    "df_concat = pd.concat(datasets, ignore_index=True)\n",
    "\n",
    "nan_count = df_concat.isna().sum()\n",
    "print(f\"\\nQuantidade dados NaN: {nan_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete dataset saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"all_stations.csv\"\n",
    "    \n",
    "path_to_csv = os.path.join(destiny_folder, dataset_name)\n",
    "df_concat.to_csv(path_to_csv, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
